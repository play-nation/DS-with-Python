{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6a43e32-0624-4a08-8766-62e8240ac203",
   "metadata": {},
   "source": [
    "## __1. Introduction to Feature Engineering__\n",
    "It refers to the process of selecting, modifying, or creating new features (variables) from the raw data to improve the performance of machine learning models.\n",
    "- It involves transforming the data into a more suitable format, making it easier for models to learn patterns and make accurate predictions.\n",
    "- It is a critical step in the data preprocessing pipeline and plays a key role in the success of machine learning projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34b3da5b-5ee4-4752-b7be-9fb5e664a7f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'HousePrices.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHousePrices.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'HousePrices.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('HousePrices.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a832e7-d94e-40e6-838f-cc3c9dbf0f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new Feature 'total_rooms' by adding bedrooms and bathrooms\n",
    "\n",
    "df['total_rooms'] = df['bedrooms']+df['bathrooms']\n",
    "print(df['total_rooms'])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a5878c-a735-4423-9455-eeb9cec8613b",
   "metadata": {},
   "source": [
    "## __3. Transforming Variables__\n",
    "Transforming variables is a crucial aspect of feature engineering that involves modifying the scale, distribution, or nature of variables to meet certain assumptions or to make them more suitable for analysis or modeling.\n",
    "- Here are a few common techniques for transforming variables:\n",
    "  \n",
    "1. Log transformation\n",
    "2. Square root transformation\n",
    "3. Box-cox transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f06d1a3-fd33-4e23-a658-efb4ae1081ff",
   "metadata": {},
   "source": [
    "### __3.1 Log Transformation__\n",
    "\n",
    "Log transformation is useful for handling skewed data or reducing the impact of outliers. It applies the natural logarithm to the variable values and makes highly skewed distributions less skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727391fc-f33f-4dc9-a484-732a1089831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logarithmic tansformation of the sqft_living column\n",
    "df['log_sqft_living'] = np.log(df['sqft_living'])\n",
    "df['log_sqft_living']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a5773-9689-418c-b956-c2a9ec5042ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdefb82-b0e4-4d9a-8989-bf8c0164e9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sqft_living'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652a02ed-059b-49b3-b020-5884239d6ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_sqft_living'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f931ae-2473-44e2-9654-59c2df5f16d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e281ba-a268-418f-8750-b1d0ca7335c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logarithmic tansformation of the price column\n",
    "df['log_price'] = np.log(df['price'])\n",
    "df['log_price']\n",
    "\n",
    "# Since we got a infinity value we will replace it with 0\n",
    "df['log_price'] = df['log_price'].replace(-np.inf,0)\n",
    "df['log_price'].min(), df['log_price'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b179a-6272-48cf-bda9-3fe5d7b2634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cddf13-772a-456f-8b42-54aa0305858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_price'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f700fbdb-7506-458e-919b-c6c4145e7425",
   "metadata": {},
   "source": [
    "### __3.2 Square Root Transformation__\n",
    "Square root transformation, like log transformation, effectively stabilizes variance and addresses skewed distributions. Although it's gentler than log transformation, it achieves the same objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed046cda-e04e-401b-9936-777d4afdb448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squareroot transformating the price variable\n",
    "\n",
    "df['sqrt_price'] = np.sqrt(df['price'])\n",
    "\n",
    "# Displaying the DataFrame with the new feature\n",
    "print(\"Dataframe with squareroot transformed price:\")\n",
    "print(df[['price','sqrt_price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d630e74-78ec-46d1-8b80-db854ecc842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sqrt_price'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17564227-04dc-404f-8cfe-e238dc6616b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf63f63d-938a-4876-9722-8311273831bf",
   "metadata": {},
   "source": [
    "### __3.3 Box-Cox Transformation__\n",
    "\n",
    "The box-cox transformation is a family of power transformations that includes log and square root transformations.\n",
    "- It can handle a broader range of data distributions.\n",
    "\n",
    "- Ensuring positive data is crucial for the Box-Cox transformation because it involves taking the logarithm, which is undefined for zero or negative values. Adding a constant helps avoid mathematical errors and ensures the transformation can be applied effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60673cf-14fc-4991-9623-982bd844c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "\n",
    "# Applying box-cox transformation to price variable\n",
    "df['bc_sqft_living']=boxcox(df['sqft_living'])\n",
    "\n",
    "# Displaying DataFrame with boxcox tranformed price variable\n",
    "\n",
    "print(df[['sqft_living','bc_sqft_living']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d7e131-93e1-47fb-a3bc-da4c89976cb8",
   "metadata": {},
   "source": [
    "## __4. Feature Scaling__\n",
    "Feature scaling is a technique used in machine learning and data preprocessing to standardize or normalize the range of independent variables or features of a dataset.\n",
    "\n",
    "- Min-max scaling transforms data to a specific range, typically between 0 and 1, preserving the relative differences between values. This normalization technique is ideal for datasets with known bounds, ensuring that all values are rescaled proportionally to fit within the specified range.\n",
    "\n",
    "- Standard scaling is preferable for normally distributed data to maintain mean-centeredness and consistent standard deviations.\n",
    "\n",
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Lesson_10_Feature_Engineering/Label_Encoding.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ff61c-ac4a-40f8-ae30-dbbcae80213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaling numeric feature using min max values\n",
    "scaler = MinMaxScaler()\n",
    "df[['sqft_living','sqft_lot']] = scaler.fit_transform(df[['sqft_living','sqft_lot']])\n",
    "df[['sqft_living','sqft_lot']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ac4a02-0a59-47ad-bf9f-f9bbb3ed3de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3c14c8-ac15-4d0b-9ff1-41bfa55ecc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_price'].var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ec6145-df25-4d62-af3c-29cc9bb6248e",
   "metadata": {},
   "source": [
    "## __5. Label Encoding__\n",
    "\n",
    "Label encoding is a technique used to convert categorical labels into a numeric format, making it suitable for machine learning algorithms that require numerical input.\n",
    "- In label encoding, each unique category is assigned an integer value.\n",
    "- This is particularly useful when dealing with ordinal categorical data, where the order of categories matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb901f46-2805-408a-8502-d477a1de6884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'size': ['small', 'medium', 'large', 'medium', 'small']}\n",
    "df1 = pd.DataFrame(data)\n",
    "\n",
    "# Before ordinal label encoding\n",
    "print(\"Original DataFrame:\")\n",
    "print(df1)\n",
    "\n",
    "# Apply label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df1['size_encoded'] = label_encoder.fit_transform(df1['size'])\n",
    "\n",
    "# After label encoding\n",
    "print(\"\\nDataFrame after label encoding:\")\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31caa6f1-97b0-4a8c-a992-98d5e1a2eba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   color\n",
      "0    red\n",
      "1   blue\n",
      "2  green\n",
      "3    red\n",
      "4  green\n",
      "\n",
      "DataFrame after one-hot encoding:\n",
      "   color_blue  color_green  color_red\n",
      "0       False        False       True\n",
      "1        True        False      False\n",
      "2       False         True      False\n",
      "3       False        False       True\n",
      "4       False         True      False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'color': ['red', 'blue', 'green', 'red', 'green']}\n",
    "df2 = pd.DataFrame(data)\n",
    "\n",
    "# Before one-hot encoding\n",
    "print(\"Original DataFrame:\")\n",
    "print(df2)\n",
    "\n",
    "# Apply one-hot encoding\n",
    "df2_encoded = pd.get_dummies(df2, columns=['color'], prefix='color')\n",
    "\n",
    "# After one-hot encoding\n",
    "print(\"\\nDataFrame after one-hot encoding:\")\n",
    "print(df2_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd014eeb-70bd-4477-b90a-6977e44ae101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrating label encoding using csv file\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label encoding for the 'city' column\n",
    "label_encoder = LabelEncoder()\n",
    "df['city_encoded'] = label_encoder.fit_transform(df['city'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d59e4-f957-437b-acad-efda1f0feb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrating one-hot encoding using csv file\n",
    "# One-Hot Encoding for the 'view' column\n",
    "df_encode = pd.get_dummies(df, columns=['price'], prefix='price')\n",
    "\n",
    "# After one-hot encoding\n",
    "print(\"\\nDataFrame after one-hot encoding:\")\n",
    "print(df_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8165e50-d531-475c-ab18-ec8139c06d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encode.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337b9e5f-6fc3-49b9-878b-99640e8e910f",
   "metadata": {},
   "source": [
    "## __7. Hashing__\n",
    "\n",
    "It is a technique to convert input data (of variable length) into a fixed-length string of characters, typically a hash code.\n",
    "- The hash function takes an input (or message) and returns a fixed-size string of characters, which is typically a hexadecimal number.\n",
    "- It is commonly used for indexing data structures, checking data integrity, and hashing passwords.\n",
    "\n",
    "\n",
    "![link text](https://labcontent.simplicdn.net/data-content/content-assets/Data_and_AI/ADSP_Images/Updated_Images/Lesson_10/10_01/Lesson_10_Feature_EngineeringHashing.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ba082c-1559-4ad2-b138-71a202e0adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Hashing in Python\n",
    "\n",
    "data = 'Hello! hashing!'\n",
    "\n",
    "# Using the hash() function\n",
    "hash_value = hash(data)\n",
    "\n",
    "print(f\" Orignial Data : {data}\")\n",
    "print(f\"\\n hash value: {hash_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f04f3-cced-4398-9089-263a273f0592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrating hashing using csv file\n",
    "# Hashing for the 'street' column\n",
    "df['street_hashed'] = df['street'].apply(hash)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dded24-921c-435d-837e-99d6504e0896",
   "metadata": {},
   "source": [
    "## __Hashlib Module__\n",
    "\n",
    "The hashlib module in Python is used for generating hash values. It offers interfaces to different cryptographic hash algorithms like MD5, SHA-1, SHA-256, SHA-384, and SHA-512.\n",
    "\n",
    "- Used for security purpose.\n",
    "- It enables the efficient use of hash functions, ensuring secure computations.\n",
    "- It provides reliability for hash-related operations.\n",
    "- It is widey used for cryptographic operations, data integrity, and password hashing.\n",
    "- It ensures convenience and robustness.\n",
    "\n",
    "Cryptographic hash algorithms vary in hash size and security levels.\n",
    "\n",
    "- For tasks where security is not a critical concern, you can opt for MD5 or SHA-1. However, it's important to note that both algorithms are deprecated due to vulnerabilities.\n",
    "\n",
    "- For security-sensitive applications, it's advisable to prioritize SHA-256, SHA-384, or SHA-512 due to their stronger security and larger hash sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b335946-5864-4807-a534-e410c858317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Hashlib module in python\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411492b-3d0f-4b62-a2ac-45f52c5fc5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "data = b\"Hello World!\"\n",
    "print(f\" Original Data: {data.decode()}\\n\")\n",
    "\n",
    "# Calculate MD5 hash\n",
    "md5_hash = hashlib.md5(data).hexdigest()\n",
    "print(f\"MD5 Hash: {md5_hash}\")\n",
    "\n",
    "# Calculate SHA-1 hash\n",
    "sha1_hash = hashlib.sha1(data).hexdigest()\n",
    "print(f\"\\nSHA-1 hash: {sha1_hash}\")\n",
    "\n",
    "# Calculate SHA-256 hash\n",
    "sha256_hash = hashlib.sha256(data).hexdigest()\n",
    "print(f\"\\nSHA-256 hash: {sha256_hash}\")\n",
    "\n",
    "# Calculate SHA-384 hash\n",
    "sha384_hash = hashlib.sha384(data).hexdigest()\n",
    "print(f\"\\nSHA-384 hash: {sha384_hash}\")\n",
    "\n",
    "# Calculate SHA-512 hash\n",
    "sha512_hash = hashlib.sha512(data).hexdigest()\n",
    "print(f\"\\nSHA-512 hash: {sha512_hash}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd4aaea-b5c4-4249-b5e3-0fbcf37a81b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrating MD5 hash function using csv file for the 'street' column\n",
    "\n",
    "street_column = df['street']\n",
    "hashed_streets = street_column.apply(lambda x: hashlib.md5(x.encode()).hexdigest())\n",
    "\n",
    "# Replace the original street values with hash values\n",
    "df['hashed_street'] = hashed_streets\n",
    "\n",
    "# Optionally, write the updated DataFrame back to a CSV file\n",
    "df.to_csv('hashed_file.csv', index=False)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78243c-0f6e-4780-aceb-d56ba7b638a6",
   "metadata": {},
   "source": [
    "## __8. Grouping Operations__\n",
    "\n",
    "Grouping operations involve splitting a dataset into groups based on some criteria, applying a function to each group independently, and then combining the results.\n",
    "- This is a crucial step in data analysis and manipulation, allowing for insights into the data at a more granular level.\n",
    "- Grouping operations are commonly combined with aggregate functions to summarize data within each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d18a2c-1528-4c74-bcf7-4c77c9e37ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame\n",
    "df3 = pd.DataFrame({'Category':['Electronics','Clothing','Electronics','Clothing','Electronics'],\n",
    "                   'Revenue':[500,700,300,400,600]})\n",
    "\n",
    "# Grouping by Categories and calculating the total revenue for each category\n",
    "\n",
    "grouped_df3 = df3.groupby('Category')['Revenue'].sum().reset_index()\n",
    "\n",
    "print(f\"Original DataFrame: {df3}\")\n",
    "print(f\"\\n Grouped DataFrame with Total Revenue: {grouped_df3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a2cd94-b463-45b6-be40-d3b4d8613d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f6e839-f85c-4c31-8c40-d3e846e313e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame\n",
    "df3 = pd.DataFrame({'Revenue':[500,700,300,400,600,1000,2000,3000,4000,5000]})\n",
    "\n",
    "for 'Revenue' in df3.column:\n",
    "    if i < 1000:\n",
    "    df3['R_Category']='Below_1000'\n",
    "else:\n",
    "    df3['R_Category']='Above_1000'\n",
    "\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9376ad-841a-48e6-9fe0-2060c6e3b191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21334128-7278-42e5-a262-a9bb1b8a0284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7ce552-6d96-408e-ac7c-90a5eae4aa2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ec7f9e-ac17-4924-8686-e82e8edd182a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8487b4-15aa-4a36-b7fe-96747a6b6aed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
